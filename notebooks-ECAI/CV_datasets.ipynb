{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import deltas\n",
    "from deltas.pipeline import data, classifier, evaluation\n",
    "from deltas.model import downsample\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "costs = (1, 1)  # change for (1, 10) to increase results\n",
    "\n",
    "datasets = {0: 'Breast Cancer', 2: 'Iris', 3: 'Wine', 4: 'Pima Indian Diabetes',\n",
    "            5: 'Sonar Rocks vs Mines', 6: 'Banknote Authentication',\n",
    "            7: 'Abalone Gender', 8: 'Ionosphere', 9: 'Wheat Seeds',\n",
    "            10: 'Credit Scoring 1', 11: 'Credit Scoring 2',\n",
    "            12: 'Direct Marketing', 13: 'Habermans breast cancer',\n",
    "            14: 'Wisconsin Breast Cancer', 15: 'Hepatitis',\n",
    "            16: 'Heart Disease'}\n",
    "\n",
    "dataset = datasets[0]  # change ind to select dataset to use\n",
    "# dataset = datasets[4]  # change ind to select dataset to use\n",
    "dataset = datasets[14]  # change ind to select dataset to use\n",
    "# dataset = datasets[15]  # change ind to select dataset to use\n",
    "dataset = datasets[16]  # change ind to select dataset to use\n",
    "model = 'SVM-rbf'\n",
    "# model = 'MLP'\n",
    "# model = 'Linear'\n",
    "\n",
    "# dataset = datasets[7]  # change ind to select dataset to use\n",
    "dfs = []\n",
    "import random\n",
    "for i in tqdm(range(10)):\n",
    "    # np.random.seed(random.randint)\n",
    "    # np.random.seed(i)\n",
    "    # data_clf = data.get_real_dataset(dataset, _print=False, seed=i, scale=True)\n",
    "    data_clf = data.get_real_dataset(dataset, _print=False, scale=True)\n",
    "    classifiers_dict = classifier.get_classifier(\n",
    "        data_clf=data_clf,\n",
    "        model=model,\n",
    "        _plot=False,\n",
    "        _print=False)\n",
    "    data_clf['clf'] = classifiers_dict['Baseline']\n",
    "    X = data_clf['data']['X']\n",
    "    y = data_clf['data']['y']\n",
    "    clf = data_clf['clf']\n",
    "    # deltas_model = downsample.downsample_deltas(\n",
    "    #     clf).fit(X, y, _print=True, _plot=True, max_trials=10000)\n",
    "    # deltas_model = base.base_deltas(\n",
    "    #     clf).fit(X, y, grid_search=True, _print=True, _plot=True)\n",
    "    param_grid = {\n",
    "                #   'alpha': [0, 0.1, 1, 10],\n",
    "                  'grid_search': [True, False],\n",
    "                  'method': ['supports-prop-update_mean', 'supports-prop-update_mean-margin_only']}\n",
    "    grid_original = GridSearchCV(\n",
    "        downsample.downsample_deltas(), param_grid, refit=True)\n",
    "    grid_original.fit(X, y,\n",
    "                      clf=clf,\n",
    "                      _print=False,\n",
    "                      _plot=False,\n",
    "                      max_trials=10000,\n",
    "                      parallel=True)\n",
    "    deltas_model = grid_original.best_estimator_\n",
    "    print(f'Best params: {grid_original.best_params_}')\n",
    "\n",
    "    if deltas_model.is_fit == True:\n",
    "        classifiers_dict['Our Method'] = deltas_model\n",
    "        scores_df = evaluation.eval_test(classifiers_dict,\n",
    "                                         data_clf['data_test'], _print=False, _plot=False)\n",
    "        dfs.append(scores_df)\n",
    "    else:\n",
    "        print('not fit deltas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)\n",
    "mean = {}\n",
    "std = {}\n",
    "index = df.index.unique().to_list()\n",
    "cols = df.columns.to_list()\n",
    "for method in index:\n",
    "    mean[method] = df.loc[method].mean().to_list()\n",
    "    std[method] = df.loc[method].std().to_list()\n",
    "\n",
    "mean_df = pd.DataFrame.from_dict(mean, orient='index', columns=cols)\n",
    "std_df = pd.DataFrame.from_dict(std, orient='index', columns=cols)\n",
    "print(dataset)\n",
    "print('mean')\n",
    "print(mean_df)\n",
    "print('\\nstd')\n",
    "print(std_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
