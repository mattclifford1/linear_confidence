{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import deltas\n",
    "from deltas.pipeline import data, classifier, evaluation\n",
    "from deltas.model import downsample\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not fit deltas\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:05<00:23,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:07<00:17,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not fit deltas\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:11<00:17,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:12<00:12,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not fit deltas\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:14<00:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not fit deltas\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:16<00:06,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:18<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not fit deltas\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "costs = (1, 1)  # change for (1, 10) to increase results\n",
    "\n",
    "datasets = {0: 'Breast Cancer', 2: 'Iris', 3: 'Wine', 4: 'Pima Indian Diabetes',\n",
    "            5: 'Sonar Rocks vs Mines', 6: 'Banknote Authentication',\n",
    "            7: 'Abalone Gender', 8: 'Ionosphere', 9: 'Wheat Seeds',\n",
    "            10: 'Credit Scoring 1', 11: 'Credit Scoring 2',\n",
    "            12: 'Direct Marketing', 13: 'Habermans breast cancer',\n",
    "            14: 'Wisconsin Breast Cancer', 15: 'Hepatitis',\n",
    "            16: 'Heart Disease'}\n",
    "\n",
    "dataset = datasets[4]  # change ind to select dataset to use\n",
    "model = 'SVM-rbf'\n",
    "# model = 'MLP'\n",
    "# model = 'Linear'\n",
    "\n",
    "# dataset = datasets[7]  # change ind to select dataset to use\n",
    "dfs = []\n",
    "data_clf_old = data.get_real_dataset(dataset, _print=False, scale=True)\n",
    "for i in tqdm(range(10)):\n",
    "    # np.random.seed(random.randint)\n",
    "    # np.random.seed(i)\n",
    "    data_clf = data.get_real_dataset(dataset, _print=False, seed=i, scale=True)\n",
    "    # data_clf = data.get_real_dataset(dataset, _print=False, scale=True)\n",
    "    print((data_clf['data']['X'] == data_clf_old['data']['X']).all())\n",
    "    data_clf_old = data_clf\n",
    "    classifiers_dict = classifier.get_classifier(\n",
    "        data_clf=data_clf,\n",
    "        model=model,\n",
    "        _plot=False,\n",
    "        _print=False)\n",
    "    data_clf['clf'] = classifiers_dict['Baseline']\n",
    "    X = data_clf['data']['X']\n",
    "    y = data_clf['data']['y']\n",
    "    clf = data_clf['clf']\n",
    "    # deltas_model = downsample.downsample_deltas(\n",
    "    #     clf).fit(X, y, _print=True, _plot=True, max_trials=10000)\n",
    "    # deltas_model = base.base_deltas(\n",
    "    #     clf).fit(X, y, grid_search=True, _print=True, _plot=True)\n",
    "    if False:\n",
    "        param_grid = {\n",
    "                    #   'alpha': [0, 0.1, 1, 10],\n",
    "                    #   'grid_search': [True, False],\n",
    "                    'method': ['supports-prop-update_mean', 'supports-prop-update_mean-margin_only']}\n",
    "        grid_original = GridSearchCV(\n",
    "            downsample.downsample_deltas(), param_grid, refit=True)\n",
    "        grid_original.fit(X, y,\n",
    "                        clf=clf,\n",
    "                        _print=False,\n",
    "                        _plot=False,\n",
    "                        max_trials=10000,\n",
    "                        parallel=True)\n",
    "        deltas_model = grid_original.best_estimator_\n",
    "        print(f'Best params: {grid_original.best_params_}')\n",
    "    else:\n",
    "        deltas_model = downsample.downsample_deltas(clf).fit(X, y,\n",
    "                                                             alpha=10,\n",
    "                                                             _print=False,\n",
    "                                                             _plot=False,\n",
    "                                                             method='supports-prop-update_mean',\n",
    "                                                             max_trials=10000,\n",
    "                                                             parallel=True)\n",
    "\n",
    "    if deltas_model.is_fit == True:\n",
    "        classifiers_dict['Our Method'] = deltas_model\n",
    "        scores_df = evaluation.eval_test(classifiers_dict,\n",
    "                                         data_clf['data_test'], _print=False, _plot=False)\n",
    "        dfs.append(scores_df)\n",
    "    else:\n",
    "        print('not fit deltas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pima Indian Diabetes\n",
      "\\begin{tabular}{@{}lrrrr@{}}\\toprule\n",
      "Methods & Accuracy & G-Mean & F1 \\\\\n",
      "\\midrule\n",
      "Baseline & $.673 \\pm .02$ & $.458 \\pm .18$ & $.352 \\pm .19$ \\\\\n",
      "SMOTE \\cite{Chawla_2002_JAIR} & $.674 \\pm .02$ & $.577 \\pm .06$ & $.480 \\pm .08$ \\\\\n",
      "BW & $.673 \\pm .02$ & $.458 \\pm .18$ & $.352 \\pm .19$ \\\\\n",
      "BMR \\cite{Bahnsen_2014_SIAM} & $\\textbf{.704} \\pm .03$ & $.674 \\pm .04$ & $.604 \\pm .05$ \\\\\n",
      "Thresh \\cite{Sheng_2006_AAAI} & $.699 \\pm .04$ & $\\textbf{.675} \\pm .04$ & $\\textbf{.614} \\pm .04$ \\\\\n",
      "Our Method & $.703 \\pm .03$ & $.659 \\pm .05$ & $.586 \\pm .06$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(dfs, axis=0)\n",
    "mean = {}\n",
    "std = {}\n",
    "index = df.index.unique().to_list()\n",
    "cols = df.columns.to_list()\n",
    "for method in index:\n",
    "    mean[method] = df.loc[method].mean().to_list()\n",
    "    std[method] = df.loc[method].std().to_list()\n",
    "\n",
    "mean_df = pd.DataFrame.from_dict(mean, orient='index', columns=cols)\n",
    "std_df = pd.DataFrame.from_dict(std, orient='index', columns=cols)\n",
    "print(dataset)\n",
    "\n",
    "m = mean_df.to_dict('list')\n",
    "s = std_df.to_dict('list')\n",
    "metrics = mean_df.columns.to_list()\n",
    "methods = mean_df.index.to_list()\n",
    "sf = 5\n",
    "for metric in metrics:\n",
    "    means = m[metric]\n",
    "    sts = s[metric]\n",
    "    mx = np.argmax(means)\n",
    "    for i in range(len(means)):\n",
    "        m_str = str(means[i])[1:sf]\n",
    "        if i == mx:\n",
    "            m_str = f\"\\\\textbf{{{m_str}}}\"\n",
    "        s_str = str(sts[i])[1:sf-1]\n",
    "        m[metric][i] = f'${m_str} \\\\pm {s_str}$'\n",
    "\n",
    "method_map = {\n",
    "    'Baseline': 'Baseline',\n",
    "    'SMOTE': \"SMOTE \\cite{Chawla_2002_JAIR}\",\n",
    "    'Balanced Weights': 'BW',\n",
    "    'BMR': 'BMR \\cite{Bahnsen_2014_SIAM}',\n",
    "    'Threshold': 'Thresh \\cite{Sheng_2006_AAAI}',\n",
    "    'Our Method': 'Our Method',\n",
    "}\n",
    "meths_new = []\n",
    "for me in methods:\n",
    "    meths_new.append(method_map[me])\n",
    "m['Methods'] = meths_new\n",
    "df = pd.DataFrame(m)  # .set_index('Methods')\n",
    "meths = df.pop('Methods')\n",
    "df.insert(0, 'Methods', meths)\n",
    "latex_str = df.to_latex(index=False)\n",
    "\n",
    "print('\\\\begin{tabular}{@{}lrrrr@{}}'+latex_str[22:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
