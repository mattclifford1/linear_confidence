{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import deltas\n",
    "from deltas.pipeline import data, classifier, evaluation\n",
    "from deltas.model import downsample\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [05:19<8:47:16, 319.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.839127  0.415354  0.198658\n",
      "SMOTE             0.822420  0.454575  0.216409\n",
      "Balanced Weights  0.841822  0.418769  0.203528\n",
      "BMR               0.863379  0.370895  0.183575\n",
      "Threshold         0.862301  0.383201  0.192733\n",
      "Our Method        0.793317  0.469261  0.208462 \n",
      "\n",
      "\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [09:47<7:52:34, 289.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.839127  0.415354  0.198658\n",
      "SMOTE             0.822420  0.454575  0.216409\n",
      "Balanced Weights  0.841822  0.418769  0.203528\n",
      "BMR               0.863379  0.370895  0.183575\n",
      "Threshold         0.862301  0.383201  0.192733\n",
      "Our Method        0.793317  0.469261  0.208462 \n",
      "\n",
      "\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [14:04<7:23:55, 274.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.814875  0.495800  0.242558\n",
      "SMOTE             0.817569  0.417866  0.185319\n",
      "Balanced Weights  0.841283  0.372276  0.166902\n",
      "BMR               0.812988  0.497365  0.242358\n",
      "Threshold         0.812988  0.497365  0.242358\n",
      "Our Method        0.756130  0.540405  0.240134 \n",
      "\n",
      "\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [18:05<6:57:44, 261.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.837780  0.451525  0.226221\n",
      "SMOTE             0.805443  0.459173  0.208333\n",
      "Balanced Weights  0.843977  0.455734  0.235139\n",
      "BMR               0.853678  0.393290  0.193165\n",
      "Threshold         0.852331  0.413125  0.208092\n",
      "Our Method        0.804096  0.481483  0.224120 \n",
      "\n",
      "\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [22:28<6:54:49, 261.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.863110  0.377166  0.188498\n",
      "SMOTE             0.829157  0.441627  0.211443\n",
      "Balanced Weights  0.839666  0.404371  0.190476\n",
      "BMR               0.867691  0.368619  0.185738\n",
      "Threshold         0.835893  0.417256  0.197628\n",
      "Our Method        0.818647  0.451077  0.211020 \n",
      "\n",
      "\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [26:38<6:43:50, 257.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.846403  0.403182  0.194915\n",
      "SMOTE             0.814336  0.461784  0.216155\n",
      "Balanced Weights  0.833738  0.411247  0.191350\n",
      "BMR               0.864726  0.380651  0.192926\n",
      "Threshold         0.825653  0.450613  0.215758\n",
      "Our Method        0.797359  0.474967  0.215031 \n",
      "\n",
      "\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [30:18<6:20:43, 245.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.818378  0.469979  0.225287\n",
      "SMOTE             0.830504  0.381916  0.166887\n",
      "Balanced Weights  0.813258  0.421967  0.185664\n",
      "BMR               0.836432  0.438510  0.214748\n",
      "Threshold         0.835893  0.438365  0.214194\n",
      "Our Method        0.782808  0.524047  0.242481 \n",
      "\n",
      "\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [34:26<6:17:23, 246.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.846403  0.394512  0.188034\n",
      "SMOTE             0.818378  0.418077  0.185990\n",
      "Balanced Weights  0.850445  0.361658  0.165414\n",
      "BMR               0.860684  0.376626  0.185827\n",
      "Threshold         0.817839  0.428364  0.193317\n",
      "Our Method        0.838319  0.401208  0.186992 \n",
      "\n",
      "\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [38:40<6:17:13, 248.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.862840  0.432283  0.234586\n",
      "SMOTE             0.820534  0.434207  0.199519\n",
      "Balanced Weights  0.836971  0.417531  0.198675\n",
      "BMR               0.837510  0.484909  0.252788\n",
      "Threshold         0.836163  0.484505  0.251232\n",
      "Our Method        0.795742  0.520667  0.248016 \n",
      "\n",
      "\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [42:39<7:11:16, 284.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy    G-Mean        F1\n",
      "Method                                        \n",
      "Baseline          0.846672  0.422725  0.210818\n",
      "SMOTE             0.836163  0.422713  0.202100\n",
      "Balanced Weights  0.850714  0.421029  0.213068\n",
      "BMR               0.866613  0.374788  0.189853\n",
      "Threshold         0.861223  0.389059  0.196568\n",
      "Our Method        0.844516  0.424872  0.210670 \n",
      "\n",
      "\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "costs = (1, 1)  # change for (1, 10) to increase results\n",
    "dataset = 'MIMIC-III-mortality'\n",
    "# model = 'SVM-rbf'\n",
    "# model = 'MLP-deep'\n",
    "model = 'MIMIC-cross-val'\n",
    "model = 'MIMIC'\n",
    "\n",
    "dfs = []\n",
    "len_required = 10\n",
    "for i in tqdm(range(len_required*10)):\n",
    "    # np.random.seed(random.randint)\n",
    "    # np.random.seed(i)\n",
    "    data_clf = data.get_real_dataset(dataset, _print=False, seed=i, scale=True)\n",
    "    # data_clf = data.get_real_dataset(dataset, _print=False, scale=True)\n",
    "    classifiers_dict = classifier.get_classifier(\n",
    "        data_clf=data_clf,\n",
    "        model=model,\n",
    "        _plot=False,\n",
    "        _print=True)\n",
    "    data_clf['clf'] = classifiers_dict['Baseline']\n",
    "    X = data_clf['data']['X']\n",
    "    y = data_clf['data']['y']\n",
    "    clf = data_clf['clf']\n",
    "    # deltas_model = downsample.downsample_deltas(\n",
    "    #     clf).fit(X, y, _print=True, _plot=True, max_trials=10000)\n",
    "    # deltas_model = base.base_deltas(\n",
    "    #     clf).fit(X, y, grid_search=True, _print=True, _plot=True)\n",
    "    if False:\n",
    "        param_grid = {\n",
    "                    #   'alpha': [0, 0.1, 1, 10],\n",
    "                    #   'grid_search': [True, False],\n",
    "                    'method': ['supports-prop-update_mean', 'supports-prop-update_mean-margin_only']}\n",
    "        grid_original = GridSearchCV(\n",
    "            downsample.downsample_deltas(), param_grid, refit=True)\n",
    "        grid_original.fit(X, y,\n",
    "                        clf=clf,\n",
    "                        _print=False,\n",
    "                        _plot=False,\n",
    "                        max_trials=10000,\n",
    "                        parallel=True)\n",
    "        deltas_model = grid_original.best_estimator_\n",
    "        print(f'Best params: {grid_original.best_params_}')\n",
    "    else:\n",
    "        deltas_model = downsample.downsample_deltas(clf).fit(X, y,\n",
    "                                                             alpha=1,\n",
    "                                                             _print=False,\n",
    "                                                             _plot=False,\n",
    "                                                             max_trials=10000,\n",
    "                                                             parallel=True)\n",
    "\n",
    "    if deltas_model.is_fit == True:\n",
    "        classifiers_dict['Our Method'] = deltas_model\n",
    "        scores_df = evaluation.eval_test(classifiers_dict,\n",
    "                                         data_clf['data_test'], \n",
    "                                         _print=True, \n",
    "                                         _plot=False)\n",
    "        dfs.append(scores_df)\n",
    "    print(len(dfs))\n",
    "    # else:\n",
    "    #     print('not fit deltas')\n",
    "    if len(dfs) == len_required:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% MIMIC-III-mortality - 10\n",
      "                  Accuracy    G-Mean        F1\n",
      "Baseline          0.841471  0.427788  0.210823\n",
      "SMOTE             0.821692  0.434651  0.200856\n",
      "Balanced Weights  0.839369  0.410335  0.195374\n",
      "BMR               0.852708  0.405655  0.202455\n",
      "Threshold         0.840259  0.428505  0.210461\n",
      "Our Method        0.802425  0.475725  0.219539\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(dfs, axis=0)\n",
    "mean = {}\n",
    "std = {}\n",
    "index = df.index.unique().to_list()\n",
    "cols = df.columns.to_list()\n",
    "for method in index:\n",
    "    mean[method] = df.loc[method].mean().to_list()\n",
    "    std[method] = df.loc[method].std().to_list()\n",
    "\n",
    "mean_df = pd.DataFrame.from_dict(mean, orient='index', columns=cols)\n",
    "std_df = pd.DataFrame.from_dict(std, orient='index', columns=cols)\n",
    "print(f'% {dataset} - {len_required}')\n",
    "\n",
    "m = mean_df.to_dict('list')\n",
    "s = std_df.to_dict('list')\n",
    "metrics = mean_df.columns.to_list()\n",
    "methods = mean_df.index.to_list()\n",
    "sf = 5\n",
    "for metric in metrics:\n",
    "    means = m[metric]\n",
    "    sts = s[metric]\n",
    "    mx = np.argmax(means)\n",
    "    for i in range(len(means)):\n",
    "        m_str = str(means[i])[1:sf]\n",
    "        if i == mx:\n",
    "            m_str = f\"\\\\textbf{{{m_str}}}\"\n",
    "        s_str = str(sts[i])[1:sf-1]\n",
    "        m[metric][i] = f'${m_str} \\\\pm {s_str}$'\n",
    "\n",
    "method_map = {\n",
    "    'Baseline': 'Baseline',\n",
    "    'SMOTE': \"SMOTE \\cite{Chawla_2002_JAIR}\",\n",
    "    'Balanced Weights': 'BW',\n",
    "    'BMR': 'BMR \\cite{Bahnsen_2014_SIAM}',\n",
    "    'Threshold': 'Thresh \\cite{Sheng_2006_AAAI}',\n",
    "    'Our Method': 'Our Method',\n",
    "}\n",
    "meths_new = []\n",
    "for me in methods:\n",
    "    meths_new.append(method_map[me])\n",
    "m['Methods'] = meths_new\n",
    "df = pd.DataFrame(m)  # .set_index('Methods')\n",
    "meths = df.pop('Methods')\n",
    "df.insert(0, 'Methods', meths)\n",
    "latex_str = df.to_latex(index=False)\n",
    "\n",
    "# print('\\\\begin{tabular}{@{}lrrrrr@{}}'+latex_str[23:])\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "save_file = os.path.join(os.path.dirname(\n",
    "    os.path.abspath('')), 'notebooks-ECAI', 'results', f'Results-5-{dataset}.txt')\n",
    "with open(save_file, \"w\") as text_file:\n",
    "    text_file.write(f'% {dt_string}\\n')\n",
    "    text_file.write(f'% {dataset} - {len_required} runs {model} model\\n')\n",
    "    train = np.unique(data_clf['data']['y'], return_counts=True)[1]\n",
    "    test = np.unique(data_clf['data_test']['y'], return_counts=True)[1]\n",
    "    text_file.write(f'% train:{train}, test:{test}\\n')\n",
    "    format = '\\\\begin{tabular}{@{}l' + 'c'*len(mean_df.columns) + '@{}}'\n",
    "    text_file.write(format+latex_str[18+len(mean_df.columns):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
