{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import deltas\n",
    "from deltas.pipeline import data, classifier, evaluation\n",
    "from deltas.model import downsample\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/99 [00:02<04:43,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/99 [00:05<04:18,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/99 [00:07<03:48,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/99 [00:09<03:32,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/99 [00:11<03:17,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/99 [00:13<03:15,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/99 [00:15<03:08,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/99 [00:18<03:26,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/99 [00:19<03:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/99 [00:21<02:54,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/99 [00:23<02:54,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/99 [00:25<02:46,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/99 [00:27<03:02,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/99 [00:29<02:49,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/99 [00:31<02:49,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/99 [00:34<02:57,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/99 [00:35<02:49,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/99 [00:38<02:59,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/99 [00:40<02:51,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/99 [00:42<02:46,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/99 [00:44<02:42,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/99 [00:46<02:40,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/99 [00:48<02:30,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/99 [00:50<02:24,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/99 [00:52<02:22,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 26/99 [00:54<02:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/99 [00:56<02:28,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/99 [00:58<02:23,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/99 [01:00<02:16,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/99 [01:02<02:26,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 31/99 [01:04<02:16,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/99 [01:06<02:14,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/99 [01:08<02:07,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/99 [01:10<02:08,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/99 [01:13<02:20,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "costs = (1, 1)  # change for (1, 10) to increase results\n",
    "\n",
    "datasets = {0: 'Breast Cancer', 2: 'Iris', 3: 'Wine', 4: 'Pima Indian Diabetes',\n",
    "            5: 'Sonar Rocks vs Mines', 6: 'Banknote Authentication',\n",
    "            7: 'Abalone Gender', 8: 'Ionosphere', 9: 'Wheat Seeds',\n",
    "            10: 'Credit Scoring 1', 11: 'Credit Scoring 2',\n",
    "            12: 'Direct Marketing', 13: 'Habermans breast cancer',\n",
    "            14: 'Wisconsin Breast Cancer', 15: 'Hepatitis',\n",
    "            16: 'Heart Disease'}\n",
    "\n",
    "dataset = datasets[4]  # change ind to select dataset to use\n",
    "model = 'SVM-rbf'\n",
    "# model = 'MLP'\n",
    "# model = 'Linear'\n",
    "\n",
    "# dataset = datasets[7]  # change ind to select dataset to use\n",
    "dfs = []\n",
    "len_required = 10\n",
    "for i in tqdm(range(1, len_required*10)):\n",
    "    data_clf = data.get_real_dataset(dataset, _print=False, seed=i, scale=True)\n",
    "\n",
    "    #check random seed is working\n",
    "    # data_clf_old = data.get_real_dataset(dataset, _print=False, seed=i, scale=True)\n",
    "    # print((data_clf['data']['X'] == data_clf_old['data']['X']).all())#\n",
    "\n",
    "    classifiers_dict = classifier.get_classifier(\n",
    "        data_clf=data_clf,\n",
    "        model=model,\n",
    "        _plot=False,\n",
    "        _print=False)\n",
    "    data_clf['clf'] = classifiers_dict['Baseline']\n",
    "    X = data_clf['data']['X']\n",
    "    y = data_clf['data']['y']\n",
    "    clf = data_clf['clf']\n",
    "    # deltas_model = downsample.downsample_deltas(\n",
    "    #     clf).fit(X, y, _print=True, _plot=True, max_trials=10000)\n",
    "    # deltas_model = base.base_deltas(\n",
    "    #     clf).fit(X, y, grid_search=True, _print=True, _plot=True)\n",
    "    if False:\n",
    "        param_grid = {\n",
    "                    #   'alpha': [0, 0.1, 1, 10],\n",
    "                    #   'grid_search': [True, False],\n",
    "                    'method': ['supports-prop-update_mean', 'supports-prop-update_mean-margin_only']}\n",
    "        grid_original = GridSearchCV(\n",
    "            downsample.downsample_deltas(), param_grid, refit=True)\n",
    "        grid_original.fit(X, y,\n",
    "                        clf=clf,\n",
    "                        _print=False,\n",
    "                        _plot=False,\n",
    "                        max_trials=10000,\n",
    "                        parallel=True)\n",
    "        deltas_model = grid_original.best_estimator_\n",
    "        print(f'Best params: {grid_original.best_params_}')\n",
    "    else:\n",
    "        deltas_model = downsample.downsample_deltas(clf).fit(X, y,\n",
    "                                                             alpha=1,\n",
    "                                                             _print=False,\n",
    "                                                             _plot=False,\n",
    "                                                             method='supports-prop-update_mean',\n",
    "                                                             max_trials=10000,\n",
    "                                                             parallel=True)\n",
    "\n",
    "    if deltas_model.is_fit == True:\n",
    "        classifiers_dict['Our Method'] = deltas_model\n",
    "        scores_df = evaluation.eval_test(classifiers_dict,\n",
    "                                         data_clf['data_test'], _print=False, _plot=False)\n",
    "        dfs.append(scores_df)\n",
    "        print(len(dfs))\n",
    "    # else:\n",
    "    #     print('not fit deltas')\n",
    "    if len(dfs) == len_required:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Pima Indian Diabetes - 10\n",
      "                  Accuracy    G-Mean   ROC-AUC        F1\n",
      "Baseline          0.540974  0.181501  0.746021  0.137286\n",
      "SMOTE             0.595132  0.495203  0.715252  0.396270\n",
      "Balanced Weights  0.540974  0.181501  0.746021  0.137286\n",
      "BMR               0.661460  0.628755  0.746021  0.575362\n",
      "Threshold         0.661460  0.628755  0.746021  0.575362\n",
      "Our Method        0.673022  0.651837  0.746021  0.611909\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(dfs, axis=0)\n",
    "mean = {}\n",
    "std = {}\n",
    "index = df.index.unique().to_list()\n",
    "cols = df.columns.to_list()\n",
    "for method in index:\n",
    "    mean[method] = df.loc[method].mean().to_list()\n",
    "    std[method] = df.loc[method].std().to_list()\n",
    "\n",
    "mean_df = pd.DataFrame.from_dict(mean, orient='index', columns=cols)\n",
    "std_df = pd.DataFrame.from_dict(std, orient='index', columns=cols)\n",
    "print(f'% {dataset} - {len_required}')\n",
    "\n",
    "m = mean_df.to_dict('list')\n",
    "s = std_df.to_dict('list')\n",
    "metrics = mean_df.columns.to_list()\n",
    "methods = mean_df.index.to_list()\n",
    "sf = 5\n",
    "for metric in metrics:\n",
    "    means = m[metric]\n",
    "    sts = s[metric]\n",
    "    mx = np.argmax(means)\n",
    "    for i in range(len(means)):\n",
    "        m_str = str(means[i])[1:sf]\n",
    "        if i == mx:\n",
    "            m_str = f\"\\\\textbf{{{m_str}}}\"\n",
    "        s_str = str(sts[i])[1:sf-1]\n",
    "        m[metric][i] = f'${m_str} \\\\pm {s_str}$'\n",
    "\n",
    "method_map = {\n",
    "    'Baseline': 'Baseline',\n",
    "    'SMOTE': \"SMOTE \\cite{Chawla_2002_JAIR}\",\n",
    "    'Balanced Weights': 'BW',\n",
    "    'BMR': 'BMR \\cite{Bahnsen_2014_SIAM}',\n",
    "    'Threshold': 'Thresh \\cite{Sheng_2006_AAAI}',\n",
    "    'Our Method': 'Our Method',\n",
    "}\n",
    "meths_new = []\n",
    "for me in methods:\n",
    "    meths_new.append(method_map[me])\n",
    "m['Methods'] = meths_new\n",
    "df = pd.DataFrame(m)  # .set_index('Methods')\n",
    "meths = df.pop('Methods')\n",
    "df.insert(0, 'Methods', meths)\n",
    "latex_str = df.to_latex(index=False)\n",
    "\n",
    "# print('\\\\begin{tabular}{@{}lrrrr@{}}'+latex_str[22:])\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "save_file = os.path.join(os.path.dirname(\n",
    "    os.path.abspath('')), 'notebooks-ECAI', 'results', f'Results-1-{dataset}.txt')\n",
    "with open(save_file, \"w\") as text_file:\n",
    "    text_file.write(f'% {dt_string}\\n')\n",
    "    text_file.write(f'% {dataset} - {len_required} runs {model} model\\n')\n",
    "    train = np.unique(data_clf['data']['y'], return_counts=True)[1]\n",
    "    test = np.unique(data_clf['data_test']['y'], return_counts=True)[1]\n",
    "    text_file.write(f'% train:{train}, test:{test}\\n')\n",
    "    text_file.write('\\\\begin{tabular}{@{}lrrrr@{}}'+latex_str[22:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
